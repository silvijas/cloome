{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a451f42-3876-4ff8-998a-f0c250814141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "src_path = os.path.split(os.getcwd())[0]\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "import re\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import itertools\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from training.datasets import CellPainting\n",
    "import clip.helpers\n",
    "\n",
    "\n",
    "\n",
    "def group_samples(indir):\n",
    "    dirlist = glob.glob(os.path.join(indir, \"*\"))           # Loads all directories from the indir\n",
    "\n",
    "    basenames = [os.path.basename(d) for d in dirlist]      # Extracts basenames for directories\n",
    " #   print(f\"group_samples() -> basenames of directory : {basenames}\")\n",
    "\n",
    "    # ME : They will be grouped and sorted based on the plates, and in our case first 7 characters are the PLATE_ID\n",
    "    plate_groups = [list(g) for _, g in itertools.groupby(sorted(basenames), lambda x: x[0:8])]\n",
    " #   print(f\"plate_groups : {plate_groups}\")\n",
    "\n",
    "    fullpath_groups = []\n",
    "    basenames_groups = []\n",
    "\n",
    "    order = [2,3,5,1,4]                      # Defining the order in which channels will be grouped\n",
    "\n",
    "    for g in plate_groups:                   # Preparing of full paths\n",
    "     #   print(f\"\\tg={g}\\n\")\n",
    "        fullpath_group = []\n",
    "        basenames_group = []\n",
    "        for f in g:\n",
    "      #      print(f\"\\t\\tf={f}\\n\")\n",
    "            fullpath_group.append(os.path.join(indir, f))\n",
    "            basenames_group.append(f)\n",
    "        fullpath_groups.append(fullpath_group)\n",
    "        basenames_groups.append(basenames_group)\n",
    "\n",
    " #   print(f\"\\nfullpath_group={fullpath_group}\\nbasenames_group={basenames_group}\\n\")\n",
    "    \n",
    "    sample_list = []\n",
    "\n",
    "    for i, plate in enumerate(fullpath_groups):\n",
    "        plate_id = basenames_groups[i][0][0:7]\n",
    "        print(f\"\\nplate_id = {plate_id}\")\n",
    "\n",
    "        plate_files = []\n",
    "        for channel in plate:\n",
    "            print(f\"\\tchannel = {channel}\")\n",
    "            z = zipfile.ZipFile(channel)     # Open .zip files and extracts the .png files\n",
    "            file_list = z.namelist()\n",
    "            for f in file_list:\n",
    "                if f.endswith(\".tiff\"):\n",
    "                    plate_files.append(f)\n",
    "              #   print(f\"\\t\\tfile = {f}\")\n",
    "\n",
    "        \n",
    "        #plate_files = [os.path.join(dirname, f) for f in plate_files]\n",
    "        \n",
    "        # Groups .png files by substring of their names and sorts the files based on the predefined order.\n",
    "  #      sample_groups = [list(g) for _, g in itertools.groupby(sorted(plate_files, key=lambda x: x[-49:-43]), lambda x: x[-49:-43])]\n",
    "\n",
    "        sample_groups = [list(g) for _, g in itertools.groupby(\n",
    "            sorted(plate_files, key=lambda x: x.split('_')[-3]),     # Extract the last character before .png\n",
    "            lambda x: x.split('_')[-3]                               # Use the last character before .png as the group key\n",
    "        )]\n",
    "\n",
    "   #     print(f\"BEFORE FOR\\n{sample_groups}\\n\\n\\n\")\n",
    "\n",
    "        for g in sample_groups:\n",
    "       #     ordered_group = [x for _, x in sorted(zip(order, g))]\n",
    "            ordered_group = sorted(g, key=lambda x: x.split('_')[1])\n",
    "            sample_list.append(ordered_group)\n",
    "\n",
    "  #  print(f\"Sample list : \\n\\t{sample_list}\")\n",
    "    \n",
    "    return sample_list                        # Returns a list of images grouped and ordered based on PLATE_ID and channels\n",
    "\n",
    "\n",
    "def process_sample(imglst, indir, outdir=\".\"):      #imglst : group of images\n",
    "  #  print(f\"process_sample()\\n{imglst}\\n\\n\")\n",
    "\n",
    "    sample = np.zeros((2500, 2500, 5), dtype=np.uint8) #520x696\n",
    "\n",
    "    refimg = imglst[0]\n",
    "\n",
    "    refimg = os.path.basename(imglst[0])\n",
    "    \n",
    "   # pattern = re.compile(\".*(?P<plate>\\d{5})\\-(?P<channel>\\w*).*\\/.*\\_(?P<well>\\w\\d{2})\\_\\w(?P<sample>\\d).*\")\n",
    "#    pattern = re.compile(r\"img_(?P<plate>\\w+)_acqid_\\d+_(?P<well>\\w\\d{2})_site_(?P<site>\\d+)_merged_channel_\\d+\\.png\")\n",
    " #   pattern = re.compile(r\"img_(?P<plate>\\w+)_acqid_\\d+_(?P<well>\\w\\d{2})_site_(?P<site>\\d+)_merged_channel_(?P<channel>\\d+)\\.png\")      # Worked (before changing to .tiff)\n",
    "    \n",
    "    pattern = re.compile(r\"(?P<plate>\\w+)_(?P<well>\\w\\d{2})_s(?P<site>\\d+)_.*_(?P<channel>\\d+)_nm_Ex.tiff\")\n",
    "\n",
    "    print(f\"\\n{refimg}\\n\")\n",
    "    ref_matches = pattern.match(refimg)\n",
    "    plate, well, site = ref_matches[\"plate\"], ref_matches[\"well\"], ref_matches[\"site\"]\n",
    "    well = well.upper()\n",
    "  \n",
    "    sampleID = \"-\".join([plate, well, site])\n",
    "    \n",
    "    print(f\"Regex\\n\\tplate={plate}\\twell={well}\\tsite={site}\\t\\tsample_ID={sampleID}\\n\")\n",
    "\n",
    "\n",
    "    filenames, channels = {}, {}\n",
    "\n",
    "    for i, imgfile in enumerate(imglst):\n",
    "    #    print(f\"imgfile={imglst}\")\n",
    "        \n",
    "        dirname = os.path.dirname(imgfile)\n",
    "        basename = os.path.basename(imgfile)\n",
    "        base, ext = os.path.splitext(basename)\n",
    "\n",
    "    #    print(f\"dirname={dirname}\\tbasename={basename}\\tbase={base}\\text={ext}\\n\")\n",
    "\n",
    "        wavelength = base.split('_')[-3]\n",
    "        wavelength_to_channel = {\n",
    "            '405': 1,\n",
    "            '488': 2,\n",
    "            '561': 3,\n",
    "            '638': 4,\n",
    "            '730': 5\n",
    "        }\n",
    "        channel_id = wavelength_to_channel.get(wavelength, \"Unknown\")\n",
    "        \n",
    "       # dirname='P102785_channel_' + str(base.split('_')[-3][0])\n",
    "        dirname='P102785_channel_' + str(channel_id)\n",
    "        zipname = os.path.join(indir, dirname+\".zip\")\n",
    "\n",
    "        z = zipfile.ZipFile(zipname)\n",
    "        data = z.read(imgfile)\n",
    "        dataenc = io.BytesIO(data)\n",
    "\n",
    "        arr = img_to_numpy(dataenc)\n",
    "    #    print(f\"\\n\\nimgfile={imgfile}\\n\\timage_to_numpy shape of array = {arr.shape}\")\n",
    "        scaled_arr = process_image(arr)\n",
    "        \n",
    " #       print(f\"imgfile = {basename}\")\n",
    "        sample[:,:,i] = scaled_arr\n",
    "\n",
    "        matches = pattern.match(basename)\n",
    "        channel = matches[\"channel\"]\n",
    "\n",
    "        channels[i] = channel\n",
    "        filenames[channel] = base\n",
    "\n",
    "  #  outfile = str(plate)+\"-\"+str(well)+\"-\"+str(sampleID)\n",
    "  #  outpath = os.path.join(outdir, outfile)\n",
    "    outpath = os.path.join(outdir, sampleID)\n",
    "    \n",
    "    print(f\"outpath = {outpath}\")\n",
    "    np.savez(outpath, sample=sample, channels=channels, filenames=filenames)\n",
    "     \n",
    "    return\n",
    "\n",
    "def img_to_numpy(file):\n",
    "    img = Image.open(file)\n",
    " #   img = img.convert('L')\n",
    "    arr = np.array(img)\n",
    "\n",
    " #   print(\"\\n\\nImg_to_numpy\")\n",
    " #   plt.imshow(img, cmap='gray')\n",
    " #   plt.show()\n",
    "    \n",
    "    return arr\n",
    "    \n",
    "def process_image(arr):\n",
    "    threshold = illumination_threshold(arr)\n",
    "    scaled_img = sixteen_to_eight_bit(arr, threshold)\n",
    "    return scaled_img\n",
    "\n",
    "# Calculates a threshold value to remove the highest percentage of pixels from an image.\n",
    "def illumination_threshold(arr, perc=0.0028):\n",
    "    \"\"\" Return threshold value to not display a percentage of highest pixels\"\"\"\n",
    "\n",
    "    perc = perc/100\n",
    "\n",
    "    h = arr.shape[0]             # Extracting number of pixels for height and width of an image.\n",
    "    w = arr.shape[1]\n",
    "\n",
    "    # Calculating number (n) of pixels to delete\n",
    "    total_pixels = h * w         \n",
    "    n_pixels = total_pixels * perc\n",
    "    n_pixels = int(np.around(n_pixels))\n",
    "    \n",
    "    # Finding the value of the pixel with the highest value (as stated in the paper it will be used to ...)\n",
    "    flat_inds = np.argpartition(arr, -n_pixels, axis=None)[-n_pixels:]\n",
    "    inds = np.array(np.unravel_index(flat_inds, arr.shape)).T\n",
    "\n",
    "#    print(f\"array shape = {arr.shape}\")\n",
    " #   print(f\"\\nillumination_threshold() : \\n\\tinds={inds}\\n\")\n",
    "    \n",
    "    max_values = [arr[i, j] for i, j in inds]\n",
    " #   max_values = [arr[tuple(ind)] for ind in inds]\n",
    "\n",
    "    threshold = min(max_values)\n",
    "\n",
    "    return threshold\n",
    "\n",
    "def sixteen_to_eight_bit(arr, display_max, display_min=0):\n",
    "    threshold_image = ((arr.astype(float) - display_min) * (arr > display_min))\n",
    "\n",
    "    scaled_image = (threshold_image * (256. / (display_max - display_min)))\n",
    "    scaled_image[scaled_image > 255] = 255\n",
    "\n",
    "    scaled_image = scaled_image.astype(np.uint8)\n",
    "\n",
    "  #  print(scaled_image.min(), scaled_image.max())\n",
    "    \n",
    " #   print(\"\\n\\n\\n\\nHEeeeeeeeeeeeeeeeeeeeeeeeeeeeeee\")\n",
    "  #  plt.imshow(threshold_image, cmap='gray')\n",
    "   # plt.show()\n",
    "    \n",
    "    return scaled_image\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    indir = \"/share/data/analyses/silvija/RT/data_cloome/our_images/preprocessing_all/channels_tiff_zip\"         # Changed from bigger to all\n",
    "    outdir = \"/share/data/analyses/silvija/RT/data_cloome/our_images/preprocessing_all/channels_tiff_npz\"\n",
    "    n_cpus = 1  #60\n",
    "\n",
    " #   index_file = \"/share/data/analyses/silvija/RT/data_cloome/our_images/metadata_P102785.csv\"                  # Used for bigger\n",
    "    index_file = \"/share/data/analyses/silvija/RT/data_cloome/our_images/preprocessing_all/metadata_P102785.csv\"\n",
    " #   input_imgs = \"/share/data/analyses/silvija/RT/data_cloome/our_images/preprocessing\"\n",
    "    input_mols = \"/share/data/analyses/silvija/RT/data_cloome/our_images/morgan_chiral_fps.hdf5\"\n",
    "    batchsize = 32\n",
    "\n",
    "    sample_groups = group_samples(indir)\n",
    "  #  print(f\"\\nsample_groups\\n{np.array(sample_groups)}\")\n",
    "    \n",
    "    sample_groups_trans = [list(i) for i in zip(*sample_groups)]\n",
    "  #  sample_groups_prefix = [['/' + elem for elem in row] for row in sample_groups_trans]\n",
    " #   print(f\"\\nsample_groups_transposed\\n{np.array(sample_groups_trans)}\")\n",
    "  \n",
    "    result = clip.helpers.parallelize(process_sample, sample_groups_trans, n_cpus, indir=indir, outdir=outdir)\n",
    " #   print(result)\n",
    "\n",
    "#     dataloader = get_dataloader(index_file, input_imgs, batchsize)\n",
    "#     mean, std = get_mean_std(dataloader, stats_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4a42d97d-18b7-4c5d-919c-d0750ae2627f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample', 'channels', 'filenames']\n",
      "sample: [[[ 4 19 44 24  9]\n",
      "  [ 4 18 47 23 10]\n",
      "  [ 4 18 42 25 10]\n",
      "  ...\n",
      "  [ 3  9 32 32 12]\n",
      "  [ 3  8 30 30 12]\n",
      "  [ 3  8 31 31 13]]\n",
      "\n",
      " [[ 3 18 43 23  9]\n",
      "  [ 4 18 45 23 11]\n",
      "  [ 4 18 42 22 10]\n",
      "  ...\n",
      "  [ 3  8 33 31 13]\n",
      "  [ 4  7 32 30 15]\n",
      "  [ 3  7 35 31 13]]\n",
      "\n",
      " [[ 4 18 42 22  7]\n",
      "  [ 3 18 42 23  8]\n",
      "  [ 4 19 41 23 10]\n",
      "  ...\n",
      "  [ 4  9 36 32 11]\n",
      "  [ 4  8 36 32 13]\n",
      "  [ 3  8 37 32 14]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 5 13 32 23  8]\n",
      "  [ 4 13 35 24  9]\n",
      "  [ 3 14 35 23  9]\n",
      "  ...\n",
      "  [ 3  3 14 29  5]\n",
      "  [ 3  4 13 28  5]\n",
      "  [ 3  3 14 30  4]]\n",
      "\n",
      " [[ 4 13 39 22 10]\n",
      "  [ 4 14 38 22  8]\n",
      "  [ 4 14 34 23  9]\n",
      "  ...\n",
      "  [ 3  3 15 29  5]\n",
      "  [ 3  3 12 27  5]\n",
      "  [ 3  3 15 28  4]]\n",
      "\n",
      " [[ 4 13 37 21  9]\n",
      "  [ 4 15 37 22 10]\n",
      "  [ 3 13 34 23 11]\n",
      "  ...\n",
      "  [ 3  3 14 30  4]\n",
      "  [ 3  3 14 27  5]\n",
      "  [ 3  3 14 29  4]]]\n",
      "channels: {0: '405', 1: '488', 2: '561', 3: '638', 4: '730'}\n",
      "filenames: {'405': 'P102785_A08_s1_x0_y0_Fluorescence_405_nm_Ex', '488': 'P102785_A08_s1_x0_y0_Fluorescence_488_nm_Ex', '561': 'P102785_A08_s1_x0_y0_Fluorescence_561_nm_Ex', '638': 'P102785_A08_s1_x0_y0_Fluorescence_638_nm_Ex', '730': 'P102785_A08_s1_x0_y0_Fluorescence_730_nm_Ex'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npz file\n",
    "data = np.load('/share/data/analyses/silvija/RT/data_cloome/our_images/preprocessing_all/channels_tiff_npz/P102785-A08-1.npz', allow_pickle=True)\n",
    "\n",
    "# Check what arrays are stored in the .npz file\n",
    "print(data.files)\n",
    "\n",
    "# Accessing each array by its name\n",
    "for key in data.files:\n",
    "    print(f\"{key}: {data[key]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79e0b03b-9def-4204-8737-2bedce21b87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample shape: (2500, 2500, 5)\n",
      "Channels: {0: '405', 1: '488', 2: '561', 3: '638', 4: '730'}\n",
      "Filenames: {'405': 'P102785_A08_s1_x0_y0_Fluorescence_405_nm_Ex', '488': 'P102785_A08_s1_x0_y0_Fluorescence_488_nm_Ex', '561': 'P102785_A08_s1_x0_y0_Fluorescence_561_nm_Ex', '638': 'P102785_A08_s1_x0_y0_Fluorescence_638_nm_Ex', '730': 'P102785_A08_s1_x0_y0_Fluorescence_730_nm_Ex'}\n"
     ]
    }
   ],
   "source": [
    "sample = data['sample']\n",
    "channels = data['channels']\n",
    "filenames = data['filenames']\n",
    "\n",
    "# Print the loaded arrays\n",
    "print(\"Sample shape:\", sample.shape)\n",
    "print(\"Channels:\", channels)\n",
    "print(\"Filenames:\", filenames)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Cloome Environment",
   "language": "python",
   "name": "cloome"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
